{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99540cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "df=pd.read_csv('../data/retail.csv',parse_dates=[\"date\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fddcd",
   "metadata": {},
   "source": [
    "Data ingestion and quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095d65de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duplicates': np.int64(3), 'missing_qty': np.int64(2), 'neg_qty': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "assert{\"store_id\",\"item_id\",\"date\",\"qty_sold\"}.issubset(df.columns)\n",
    "dup = df.duplicated([\"store_id\",\"item_id\",\"date\"]).sum()\n",
    "missing = df[\"qty_sold\"].isna().sum()\n",
    "neg = (df[\"qty_sold\"]<0).sum()\n",
    "print({\"duplicates\":dup, \"missing_qty\":missing, \"neg_qty\":neg})\n",
    "# Remove stockout-censored rows when possible\n",
    "if \"stockout_flag\" in df:\n",
    "    df = df[df[\"stockout_flag\"]==0].copy()\n",
    "# Fill promo/price na\n",
    "for c in [\"on_promo\",\"discount_pct\",\"price\"]:\n",
    "    if c in df: df[c] = df[c].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c6f82",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb37094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.000000\n",
      "mean     0.187500\n",
      "std      0.239357\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.125000\n",
      "75%      0.312500\n",
      "max      0.500000\n",
      "Name: p_zero, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "g = df.groupby([\"item_id\"])[\"qty_sold\"].apply(lambda s: (s==0).mean()).rename(\"p_zero\")\n",
    "print(g.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d2115",
   "metadata": {},
   "source": [
    "Feature Engineering (Stat + ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f69637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Limited history - using shorter lags\n",
      "‚úÖ Features ready: 14 rows, 17 features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Sort properly\n",
    "# ---------------------------------------------------------\n",
    "df = df.sort_values([\"store_id\", \"item_id\", \"date\"])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Calendar features (always works)\n",
    "# ---------------------------------------------------------\n",
    "df[\"dow\"] = df[\"date\"].dt.weekday\n",
    "df[\"week_of_year\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SAFE Lag features (check data exists first)\n",
    "# ---------------------------------------------------------\n",
    "g = df.groupby([\"store_id\", \"item_id\"])[\"qty_sold\"]\n",
    "\n",
    "# Only create lags if enough history exists\n",
    "if len(df) >= 28:\n",
    "    df[\"lag_1\"]  = g.shift(1)\n",
    "    df[\"lag_7\"]  = g.shift(7)\n",
    "    df[\"lag_14\"] = g.shift(14)\n",
    "    df[\"lag_28\"] = g.shift(28)\n",
    "else:\n",
    "    df[\"lag_1\"] = g.shift(1)\n",
    "    df[\"lag_7\"] = g.shift(7)\n",
    "    print(\"‚ö†Ô∏è Limited history - using shorter lags\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SAFE Rolling features\n",
    "# ---------------------------------------------------------\n",
    "df[\"r7_mean\"]  = g.shift(1).rolling(7, min_periods=1).mean()\n",
    "df[\"r14_mean\"] = g.shift(1).rolling(14, min_periods=1).mean()\n",
    "df[\"r28_mean\"] = g.shift(1).rolling(28, min_periods=3).mean()\n",
    "\n",
    "df[\"r7_std\"]   = g.shift(1).rolling(7, min_periods=1).std()\n",
    "df[\"r14_max\"]  = g.shift(1).rolling(14, min_periods=1).max()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# RELAXED: Only drop rows missing TARGET (not features)\n",
    "# ---------------------------------------------------------\n",
    "df = df.dropna(subset=[\"qty_sold\"]).reset_index(drop=True)\n",
    "print(f\"‚úÖ Features ready: {df.shape[0]} rows, {len([c for c in df.columns if 'lag_' in c or 'r' in c])} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4cc0d",
   "metadata": {},
   "source": [
    "Modeling Strategy (Hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8172349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GroupKFold\n",
    "features = [c for c in df.columns if c not in [\"qty_sold\",\"date\"]]\n",
    "X, y = df[features], df[\"qty_sold\"]\n",
    "# Grouped CV by SKU-store to respect time locality across groups\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = df[\"store_id\"].astype(str) + \"_\" + df[\"item_id\"].astype(str)\n",
    "rf = RandomForestRegressor(n_estimators=400, max_depth=12, random_state=13, n_jobs=-1)\n",
    "# (Time-series CV is better: for production use expanding windows per group)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c6eb0",
   "metadata": {},
   "source": [
    " Intermittent Demand: Croston/SBA Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "277c8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def croston_forecast(y, alpha=0.1, h=4):\n",
    "    # y: pandas Series (demand), h: horizon (periods)\n",
    "    import numpy as np\n",
    "    demand = y.values\n",
    "    n = len(demand)\n",
    "    z = demand[demand>0]\n",
    "    p = np.diff(np.r_[0, np.where(demand>0)[0]])\n",
    "    if len(z)==0: return np.zeros(h)\n",
    "    z_hat, p_hat = z[0], p[1] if len(p)>1 else 1\n",
    "    for i in range(1, len(z)):\n",
    "        z_hat = alpha*z[i] + (1-alpha)*z_hat\n",
    "    for i in range(1, len(p)):\n",
    "        p_hat = alpha*p[i] + (1-alpha)*p_hat\n",
    "    f = (z_hat/p_hat) * np.ones(h)      # Croston\n",
    "    return f  # SBA variant multiplies by (1 - alpha/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c2cd2",
   "metadata": {},
   "source": [
    "Backtesting & Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4a2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase(y_true, y_pred, y_naive):\n",
    "    d = np.abs(y_true - y_pred).mean()\n",
    "    d_naive = np.abs(y_true - y_naive).mean()\n",
    "    return d/d_naive if d_naive>0 else np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0dca1",
   "metadata": {},
   "source": [
    "Inventory Optimization Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37fb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def inventory_policy(forecast, resid_std, on_hand, lead_time, \n",
    "                     annual_demand, ordering_cost, unit_cost, holding_rate,\n",
    "                     service=0.95):  \n",
    "    z = norm.ppf(service)\n",
    "    mu_L = forecast[:lead_time].sum()\n",
    "    sigma_L = resid_std * (lead_time ** 0.5)\n",
    "    SS = z * sigma_L\n",
    "    ROP = mu_L + SS\n",
    "    H = unit_cost * holding_rate\n",
    "    EOQ = np.sqrt((2 * annual_demand * ordering_cost) / H) if H > 0 else mu_L\n",
    "    order_qty = max(0, max(EOQ, ROP - on_hand))\n",
    "    return dict(mu_L=mu_L, sigma_L=sigma_L, SS=SS, ROP=ROP, EOQ=EOQ, order_qty=order_qty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911ed569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping non-numeric: category\n",
      "‚ö†Ô∏è Skipping non-numeric: brand\n",
      "‚ö†Ô∏è Skipping non-numeric: pack_size\n",
      "‚ö†Ô∏è Skipping non-numeric: city\n",
      "‚ö†Ô∏è Skipping non-numeric: cluster\n",
      "‚úÖ Using 23 numeric features\n",
      "‚úÖ STEP 9 COMPLETE | retail_forecast_model.pkl SAVED\n",
      "üé¨ streamlit run dashboard.py\n"
     ]
    }
   ],
   "source": [
    "# ===== STEP 9: PRODUCTION EXPORT (FIXED - No string errors!) =====\n",
    "import joblib\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# YOUR features - EXCLUDE categorical columns!\n",
    "exclude_cols = [\"qty_sold\", \"date\", \"store_id\", \"item_id\"]\n",
    "features = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "# ‚úÖ FIX: Select only NUMERIC columns\n",
    "numeric_features = []\n",
    "for col in features:\n",
    "    if df[col].dtype in ['float64', 'int64', 'float32', 'int32']:\n",
    "        numeric_features.append(col)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping non-numeric: {col}\")\n",
    "\n",
    "print(f\"‚úÖ Using {len(numeric_features)} numeric features\")\n",
    "\n",
    "# ‚úÖ SAFE conversion\n",
    "X = df[numeric_features].astype(float)\n",
    "y = df[\"qty_sold\"]\n",
    "groups = df[\"store_id\"].astype(str) + \"_\" + df[\"item_id\"].astype(str)\n",
    "\n",
    "# Train YOUR model\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=13)\n",
    "tr_idx, te_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, max_depth=12, random_state=13, n_jobs=-1)\n",
    "rf.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "\n",
    "# YOUR residuals\n",
    "resid_std = float(np.std(y.iloc[te_idx] - rf.predict(X.iloc[te_idx])))\n",
    "\n",
    "# ‚úÖ EXPORT - Your functions already defined above!\n",
    "artifacts = {\n",
    "    'model': rf,\n",
    "    'features': numeric_features,  # Only numeric!\n",
    "    'resid_std': resid_std,\n",
    "    'p_zero_stats': g.describe().to_dict()\n",
    "}\n",
    "\n",
    "joblib.dump(artifacts, \"retail_forecast_model.pkl\")\n",
    "print(\"‚úÖ STEP 9 COMPLETE | retail_forecast_model.pkl SAVED\")\n",
    "print(\"üé¨ streamlit run dashboard.py\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
